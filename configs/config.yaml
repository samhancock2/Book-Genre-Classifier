dataset:
  path: "data/processed/full_2k.csv"
  test_size: 0.1
  val_size: 0.111
  random_state: 13
  embedding_type: "glove"  # 'glove' or 'sentence_transformers'
  transformer_model: "all-MiniLM-L6-v2"
  device: "cuda"

embedding:
  dim: 300 # 50, 100, 200, 300 for glove.

training:
  epochs: 50
  batch_size: 32
  lr: 0.001
  early_stopping_patience: 7

model:
  type: "simple_nn"
  hidden_dim: 128
