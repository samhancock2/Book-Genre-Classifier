{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e13ca9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "from torchtext.vocab import GloVe\n",
    "import torchtext\n",
    "from torchtext.data import get_tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd37196b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../data/processed/full_2k.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a26fe03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Russian author offers an affectionate chro...</td>\n",
       "      <td>Biography</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"The Bible and the social and moral consequenc...</td>\n",
       "      <td>Religion</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A New York Times Notable Book of the YearThis ...</td>\n",
       "      <td>Biography</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It was a wonderful summer, a great memory, the...</td>\n",
       "      <td>General</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>For the first time ever, veteran World War II ...</td>\n",
       "      <td>History</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Description   Category  label\n",
       "0  The Russian author offers an affectionate chro...  Biography      0\n",
       "1  \"The Bible and the social and moral consequenc...   Religion      8\n",
       "2  A New York Times Notable Book of the YearThis ...  Biography      0\n",
       "3  It was a wonderful summer, a great memory, the...    General      3\n",
       "4  For the first time ever, veteran World War II ...    History      4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "df['label'] = le.fit_transform(df['Category'])\n",
    "num_classes = len(le.classes_)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98d0729b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "df['cleaned_desc'] = df['Description'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89273f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 27543, Val: 3443, Test: 3443\n"
     ]
    }
   ],
   "source": [
    "# First, split off 10% test\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    df['cleaned_desc'], df['label'], \n",
    "    test_size=0.1, stratify=df['label'], random_state=13)\n",
    "\n",
    "# Then split temp into train and val\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    test_size=0.11111111111111,\n",
    "    stratify=y_temp, random_state=13)\n",
    "\n",
    "print(f\"Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b8ed510",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = GloVe(name='6B', dim=300)\n",
    "\n",
    "def sentence_to_sequence(sentence, glove, max_len=300):\n",
    "    \"\"\"\n",
    "    Convert a sentence into a tensor of GloVe vectors (seq_len, embedding_dim).\n",
    "    Pads or truncates to max_len.\n",
    "    \"\"\"\n",
    "    # Handle empty / NaN sentences\n",
    "    if not isinstance(sentence, str) or len(sentence.strip()) == 0:\n",
    "        return torch.zeros(max_len, glove.dim)\n",
    "    \n",
    "    words = sentence.split()\n",
    "    vecs = [glove[word] for word in words if word in glove.stoi]\n",
    "\n",
    "    # If sentence has fewer than max_len words → pad\n",
    "    if len(vecs) < max_len:\n",
    "        padding = [torch.zeros(glove.dim) for _ in range(max_len - len(vecs))]\n",
    "        vecs.extend(padding)\n",
    "    else:\n",
    "        vecs = vecs[:max_len]  # truncate\n",
    "    \n",
    "    return torch.stack(vecs)  # shape: (max_len, glove.dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a79c51a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_seq = torch.stack(X_train.apply(lambda x: sentence_to_sequence(x, glove, max_len=300)).tolist())\n",
    "X_val_seq = torch.stack(X_val.apply(lambda x: sentence_to_sequence(x, glove, max_len=300)).tolist())\n",
    "X_test_seq = torch.stack(X_test.apply(lambda x: sentence_to_sequence(x, glove, max_len=300)).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3bca9c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27543, 300, 300])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a3cb21bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_loader = DataLoader(TextDataset(X_train_seq, y_train_tensor), batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(TextDataset(X_val_seq, y_val_tensor), batch_size=32)\n",
    "test_loader = DataLoader(TextDataset(X_test_seq, y_test_tensor), batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "52a2eb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm \n",
    "\n",
    "# ✅ 1. Check for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ✅ 2. Define GRU model\n",
    "class GRUNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_classes, num_layers=1, bidirectional=False):\n",
    "        super(GRUNet, self).__init__()\n",
    "        self.gru = nn.GRU(\n",
    "            input_dim,\n",
    "            hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=bidirectional\n",
    "        )\n",
    "        direction_factor = 2 if bidirectional else 1\n",
    "        self.fc = nn.Linear(hidden_dim * direction_factor, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, seq_len, input_dim)\n",
    "        out, _ = self.gru(x)\n",
    "        out = out[:, -1, :]  # last time step output\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# ✅ 3. Initialize model, loss, and optimizer\n",
    "input_dim = 300       # GloVe dimension\n",
    "hidden_dim = 128\n",
    "num_classes = len(y_train_tensor.unique())\n",
    "\n",
    "model = GRUNet(input_dim, hidden_dim, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "afa4dadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 861/861 [00:27<00:00, 31.68it/s]\n",
      "Epoch 1/10 [Val]: 100%|██████████| 108/108 [00:03<00:00, 29.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] Train Loss: 1.9226 | Train Acc: 0.3711 | Val Loss: 0.9504 | Val Acc: 0.6634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 861/861 [00:38<00:00, 22.22it/s]\n",
      "Epoch 2/10 [Val]: 100%|██████████| 108/108 [00:04<00:00, 24.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10] Train Loss: 0.8123 | Train Acc: 0.7123 | Val Loss: 0.7312 | Val Acc: 0.7383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 861/861 [00:22<00:00, 38.97it/s]\n",
      "Epoch 3/10 [Val]: 100%|██████████| 108/108 [00:02<00:00, 37.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10] Train Loss: 0.6453 | Train Acc: 0.7724 | Val Loss: 0.6720 | Val Acc: 0.7595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]: 100%|██████████| 861/861 [00:11<00:00, 73.21it/s]\n",
      "Epoch 4/10 [Val]: 100%|██████████| 108/108 [00:00<00:00, 159.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10] Train Loss: 0.5533 | Train Acc: 0.8060 | Val Loss: 0.6600 | Val Acc: 0.7685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 [Train]: 100%|██████████| 861/861 [00:12<00:00, 66.69it/s]\n",
      "Epoch 5/10 [Val]: 100%|██████████| 108/108 [00:00<00:00, 151.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10] Train Loss: 0.4722 | Train Acc: 0.8349 | Val Loss: 0.6551 | Val Acc: 0.7807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 [Train]: 100%|██████████| 861/861 [00:21<00:00, 39.23it/s]\n",
      "Epoch 6/10 [Val]: 100%|██████████| 108/108 [00:00<00:00, 161.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10] Train Loss: 0.4007 | Train Acc: 0.8595 | Val Loss: 0.6946 | Val Acc: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 [Train]: 100%|██████████| 861/861 [00:09<00:00, 90.21it/s]\n",
      "Epoch 7/10 [Val]: 100%|██████████| 108/108 [00:00<00:00, 151.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10] Train Loss: 0.3298 | Train Acc: 0.8858 | Val Loss: 0.7379 | Val Acc: 0.7729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 [Train]: 100%|██████████| 861/861 [00:13<00:00, 64.66it/s]\n",
      "Epoch 8/10 [Val]: 100%|██████████| 108/108 [00:00<00:00, 152.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10] Train Loss: 0.2645 | Train Acc: 0.9094 | Val Loss: 0.8211 | Val Acc: 0.7630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 [Train]: 100%|██████████| 861/861 [00:09<00:00, 89.17it/s]\n",
      "Epoch 9/10 [Val]: 100%|██████████| 108/108 [00:00<00:00, 162.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10] Train Loss: 0.2139 | Train Acc: 0.9304 | Val Loss: 0.8846 | Val Acc: 0.7668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 [Train]: 100%|██████████| 861/861 [00:09<00:00, 89.17it/s]\n",
      "Epoch 10/10 [Val]: 100%|██████████| 108/108 [00:00<00:00, 157.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] Train Loss: 0.1652 | Train Acc: 0.9466 | Val Loss: 0.9588 | Val Acc: 0.7671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # ---- Training ----\n",
    "    model.train()\n",
    "    train_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for X_batch, y_batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\"):\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * X_batch.size(0)\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        correct += (predicted == y_batch).sum().item()\n",
    "        total += y_batch.size(0)\n",
    "\n",
    "    train_acc = correct / total\n",
    "    train_loss /= total\n",
    "\n",
    "    # ---- Validation ----\n",
    "    model.eval()\n",
    "    val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\"):\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "\n",
    "            val_loss += loss.item() * X_batch.size(0)\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            val_correct += (predicted == y_batch).sum().item()\n",
    "            val_total += y_batch.size(0)\n",
    "\n",
    "    val_acc = val_correct / val_total\n",
    "    val_loss /= val_total\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
    "          f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} \"\n",
    "          f\"| Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75258ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glove-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
